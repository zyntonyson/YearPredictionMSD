---
title: "Aplicación de modelos de regresión para predecir el año de lanzamiento de una canción a partir de las características del audio"
affiliation:
  ## use one only of the following
  # author-columnar: true         ## one column per author
  institution-columnar: true  ## one column per institution (multiple autors eventually)
  # wide: true                  ## one column wide author/affiliation fields

  institution:
    - name: Estudiantes de la maestría en cómputo estadístico
      department: CENTRO DE INVESTIGACIÓN EN MATEMÁTICAS AC
      location: Unidad Monterrey
      mark: 1
      author:
        - name: Aguayo M, Ester
        - name: Castillo C, Román
    
abstract: |
  Se presenta el trabajo como reporte final de la materia 'Cómputo Estadístico', se explora la  eficacia de métodos lineales y lineales generalizados para la predicción del año de lanzamiento de una canción. Tambien se presenta la comparacíón con otros métodos de clasificación
header-includes:
  \usepackage{graphicx}
  \usepackage{amsmath}
  \usepackage{amsfonts}
  \usepackage{amssymb}
  \usepackage{algorithm}
  \usepackage{algorithmic}
  \usepackage{array}
  \usepackage{float}
  \usepackage{longtable} 
  \renewcommand{\figurename}{Figura}
  \renewcommand{\tablename}{Tabla}
  \setcounter{tocdepth}{5} 
  \setcounter{secnumdepth}{5} 
number_sections: TRUE 
bibliography: mybibfile.bib
output: rticles::ieee_article
---

```{r setup, include=FALSE}
library(readxl)
library(tidyverse)
library(GGally)
library(corrplot)
library(knitr)
library(xtable)
library(broom)
library(gridExtra)
library(leaps)
library(MASS)
library(glmnet)


knitr::opts_chunk$set(echo = FALSE, message=FALSE, out.width='60%', fig.pos= "H",fig.align='center' , warning = FALSE,comment=NA)

#Datos crudos
data <- read_csv("data/YearPredictionMSD.txt", 
                 col_names = FALSE)

# Agregar nombres a columnas para identificacion
# 1-year
# 2-13 TimbreAvg1-12
# 14-91 TimbreCov1-78
# 

names(data)<-c('year',
               sapply(1:12,function(x){paste('TimbreAvg',x,sep='')}),
               sapply(1:78,function(x){paste('TimbreCov',x,sep='')}))

#*********************** SEPARAR TRAIN Y TEST ***************************


#importante la semilla
n = nrow(data)
p<-0.6
set.seed(1)
muestra <- sample(1:nrow(data), n*p)

```


Introducción
=============

Los métodos de predicción consiste una herramienta fundamental en esta época de la abundancia de datos. Muchos negocios, día con  día producen enormes cantidades de nueva información, por ejemplo en la industría musical, horas de nueva música. Una tarea de interés, es poder determinar el año de lanzamiento. Como  parte de los recursos para la solución de esta tarea, se cuenta con el *Million Song Dataset* (MSD) que es un *data* de acceso gratuito de características de audio y metadatos de un millón de piezas musicales contemporaneas. Entre los metadatos disponibles se encuetra el año de lanzamiento de cada pieza.

## Objetivos

Usando el **MSD** se plantean los siguientes objetivos

1. Considerando al año de lanzamiento como variable númerica continua, ajustar un modelo de regresión, usando como predictores características del audio

1. Ajustar un clasificador basado en regresión multiclase para predecir el año de lanzamiento de una canción

1. Comparar los resultados con otros clasificadores tales como SVM y NN


Métodos y resultados
=============

## Análisis exploratorio

**YearPredictionMSD** es un *subset* del **MSD**, destinado a la tarea de prediccón del  año de lanzamiento de un track. Esta formado por 515345 registros de canciones correspondientes a 90 características tomadas de cada composición. Las características fueron obtenidas del API de **Echo Nest**. Donde cada composición fue divida en doce segmentos. De los cuales se recuperan los promedios y covarianzas de  todos ellos.

Con respecto a la cantidad de registros por año de lanzamiento, el conjunto de datos se encuetra altamente desbalanceado. Más del 80% correponde a canciones a partir de la primera decada del año 2000.

```{r fig.cap='Distribución de las canciones por año'}
ggplot(data) + aes(year)+geom_histogram()
```





```{r }
# Presenta el MSE a diferente número de predictores
mse_plot<-function(mse,sub,ylab)
{
  plot(1:length(mse),mse_train,
     type='b',
     col='darkblue',
     pch=19,
     xlab='Cantidad de predictores',
     ylab=ylab,
     #main = 'Subset Selection',
     sub = sub)
                        
points(which.min(mse),min(mse),col='red',pch='*',cex=2)
text(which.min(mse),min(mse),labels =bquote(paste('Mejor modelo:',.(which.min(mse)),' predictores')),pos = 3, cex=0.8 )

  
  }
```



##  Regresión múltiple

```{r}
# Seleccion datos de entrenamiento
#dividimos nuestros datos en prueba y validación
X_tr = as.matrix(data[muestra,-1])
Y_tr = as.matrix(data[muestra,1])

X_te = as.matrix(data[-muestra,-1])
Y_te = as.matrix(data[-muestra,1])

```



### Regresión ordinaria (mejor subconjunto)


En primera instancia aplicamos un modelo de regresión múltiple al conjunto de datos

Agregar el resumen de la regresión

Obtenemos un $R^2$ ajustado mucho menor de lo que esperamos, así que desde este punto podemos inferir que quizá el análisis con regresión lineal no es el óptimo


```{r}
nVar<-90
# seleccion mejor subconjunto de variables

modelo_fw <- regsubsets(X_tr, Y_tr, method = "forward",  nvmax = nVar)
modelo_bw <- regsubsets(X_tr, Y_tr, method = "backward", nvmax = nVar)

```

Dado el gran número de variables, aplicaremos métodos de selección de mejores subconjuntos, para poder trabajar con menos variables.
Tomando como valor de referencia el error cuadrático, podemos revisar como evoluciona al incrementar el número de variables.
Es bien sabido que la mejor forma de seleccionar estas variables es haciendo todas las combinaciones posibles de las mismas, pero debido al costo computacional, aplicaremos esta selección con 2 *criterios* paso forward y paso backward


* Forward stepwise selection

Podemos revisar que ambos modelos son muy similares para diferentes métricas como son R2, BIC, AIC, así que tomar alguno de ellos podrá darnos resultados similares.

 
```{r fig.cap='Forward stepwise selection'}
#modelo con paso fwd
msum_fwd  <- summary(modelo_fw )

# Calculo del MSE train
test.mat<-model.matrix(year~.,data=data)
mse_test<-rep(0,nVar)
mse_train<-rep(0,nVar)

for (i in 1:nVar)
{
   coefi = coef(modelo_fw, id=i)
   pred = test.mat[,names(coefi)]%*%coefi
   mse_train[i] = mean((data$year[muestra]-pred[muestra])^2)
   mse_test[i] = mean((data$year[-muestra]-pred[-muestra])^2)
  
}

#grafica
#grafica
par(mfrow=c(2,2))
plot(msum_fwd$adjr2 ,xlab="Núm Variables",ylab="R cuadrado aj",type="l", pch=19, col="#95505c")
points(which.max(msum_fwd$adjr2),max(msum_fwd$adjr2),col='red',pch='*',cex=2)
plot(msum_fwd$bic ,xlab="Núm Variables", ylab="Bic",type="l", pch=19, col="#5c9550")
points(which.min(msum_fwd$bic),min(msum_fwd$bic),col='red',pch='*',cex=2)
plot(msum_fwd$cp ,xlab="Núm Variables",ylab="Cp", type="l", pch=19, col="#505c95")
points(which.min(msum_fwd$cp),min(msum_fwd$cp),col='red',pch='*',cex=2)
plot(1:nVar,mse_train,xlab="Núm Variables",ylab="MSE", type="l", pch=19, col="firebrick")
lines(1:nVar,mse_test,type="l", pch=19, col="firebrick")
points(which.min(mse_test),min(mse_test),col='red',pch='*',cex=2)

```

```{r fig.cap="MSE Forward Selection"}

mse_test_fw <- vector()

for (i in 1:nVar){
  coefs <- coef(modelo_fw,i)
  indice <- match(names(coefs)[-1],colnames(X_te))
  X1_test <- cbind(1,X_te[,indice])
  Y_gorro <- X1_test%*%coefs
  mse_test_fw <- c(mse_test_fw, mean((Y_te-Y_gorro)^2))    
}

plot(mse_test_fw,type="b", pch=19, 
     ylab="Error cuadrático Medio - PRUEBA",
     xlab="Número de variables", main ="Modelo Paso Forward", col="#1f66e5" )

```


* Backward stepwise selection

Podemos revisar que ambos modelos son muy similares para diferentes métricas como son R2, BIC, AIC, así que tomar alguno de ellos podrá darnos resultados similares.


```{r  fig.cap='Backward stepwise selection'}
msum_bwd  <- summary(modelo_bw )
#grafica
# Calculo del MSE train
#test.mat<-model.matrix(year~.,data=data)
mse_test<-rep(0,nVar)
mse_train<-rep(0,nVar)

for (i in 1:nVar)
{
   coefi = coef(modelo_bw, id=i)
   pred = test.mat[,names(coefi)]%*%coefi
   mse_train[i] = mean((data$year[muestra]-pred[muestra])^2)
   mse_test[i] = mean((data$year[-muestra]-pred[-muestra])^2)
  
}

#grafica
par(mfrow=c(2,2))
plot(msum_bwd$adjr2 ,xlab="Núm Variables",ylab="R cuadrado aj",type="l", pch=19, col="#95505c")
points(which.max(msum_bwd$adjr2),max(msum_bwd$adjr2),col='red',pch='*',cex=2)
plot(msum_bwd$bic ,xlab="Núm Variables", ylab="Bic",type="l", pch=19, col="#5c9550")
points(which.min(msum_bwd$bic),min(msum_bwd$bic),col='red',pch='*',cex=2)
plot(msum_bwd$cp ,xlab="Núm Variables",ylab="Cp", type="l", pch=19, col="#505c95")
points(which.min(msum_bwd$cp),min(msum_bwd$cp),col='red',pch='*',cex=2)
plot(1:nVar,mse_train,xlab="Núm Variables",ylab="MSE", type="l", pch=19, col="firebrick")
lines(1:nVar,mse_test,type="l", pch=19, col="firebrick")
points(which.min(mse_test),min(mse_test),col='red',pch='*',cex=2)

```

```{r fig.cap="MSE Backward Selection"}

mse_test_bw <- vector()

for (i in 1:nVar){
  coefs <- coef(modelo_bw,i)
  indice <- match(names(coefs)[-1],colnames(X_te))
  X1_test <- cbind(1,X_te[,indice])
  Y_gorro <- X1_test%*%coefs
  mse_test_bw <- c(mse_test_bw, mean((Y_te-Y_gorro)^2))    
}

plot(mse_test_bw,type="b", pch=19, 
     ylab="Error cuadrático Medio - PRUEBA",
     xlab="Número de variables", main ="Modelo Paso Backward", col="#1f66e5" )

```


### Regresión con contracción  Lasso

Para enriquecer el modelo, aplicaremos Regresión Lasso, pues además de transformar los coeficiente del modelo, aplica una penalización que nos puede ayudar a seleccionar variables, debido a que algunos de los coeficientes los tornará 0.


```{r fig.cap="Modelo Lasso"}
# REGRESION LASSO

mat_tr <- model.matrix(year ~ ., data = data[muestra,])
mat_te <- model.matrix(year ~ ., data = data[-muestra,])


# Conjunto de valores de lambda 
lambda = 10 ^ seq(from = -4, to = 4, length = 100)
# 10-fold cross validation para obtener el mejor lambda
set.seed(8)
#set.seed(1)
#cv_error_lasso <- cv.glmnet(x = x, y = y, alpha = 1, nfolds = 10)
cv_lasso <- cv.glmnet(x = mat_tr, y = Y_tr, alpha = 1, lambda = lambda, thresh = 1e-12, type.measure="mse",nfolds = 10)
plot(cv_lasso)
l_lasso <- cv_lasso$lambda.min
#l_lasso <- cv_lasso$lambda.1se

#modelo lasso
model_lasso <- glmnet (mat_tr,Y_tr, alpha =1, lambda =l_lasso, thresh =1e-8) 

#evaluamos el modelo
ypred_lasso <- predict(model_lasso ,s=l_lasso ,newx=mat_te) 
#error cuadrático medio de prueba
msete_lasso <- mean((ypred_lasso - Y_te)^2)



```





###  Regresión con componentes principales

Otra manera de disminuir dimensión es a través del modelo PCR (Principal Component Regression) en donde aplicamos PCA a los datos y vamos calculando métricas que nos ayuden a decidir cuál es el mejor modelo.


```{r}
model_pcr <- pcr(year ~ ., data=data[muestra,], scale=TRUE,validation ="CV")
summary(model_pcr)

validationplot(model_pcr,val.type="MSEP")

#Evaluamos el modelo
ypred_pcr <- predict(model_pcr, X_te, ncomp=30) [,1,]
msete_pcr <- mean((ypred_pcr- Y_te)^2) 


valores_testMSE <- data.frame(metodo = c("OLS", "Forward Select","Backward Select", "PCR",
                                         "Lasso"),
                              MSE_te = c(mse_test_ols, mse_test_fw[30], mse_test_bw[30],
                                         msete_pcr, msete_lasso))

ggplot(data = valores_testMSE, aes(x = metodo, y = MSE_te)) +
  geom_col(width = 0.5, fill="#2b602c") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+ xlab("Método") + ylab("MSE Test")              

```



Revisando los errores de prueba, podemos observar que no existe un cambio muy significativo en utilizar todas las variables (90) o un tercio de ellas, por lo que seleccionaremos entonces un modelo reducido.

```{r fig.cap=PCR}
model_pcr <- pcr(year ~ ., data=data[muestra,], scale=TRUE,validation ="CV")
#summary(model_pcr)

validationplot(model_pcr,val.type="MSEP")

#Evaluamos el modelo
ypred_pcr <- predict(model_pcr, X_te, ncomp=30) [,1,]
msete_pcr <- mean((ypred_pcr- Y_te)^2) 

```

```{r fig.cap=Comparación MSE para modelos}
valores_testMSE <- data.frame(metodo = c("OLS", "Forward Select","Backward Select", "PCR",
                                         "Lasso"),
                              MSE_te = c(mse_test_ols, mse_test_fw[30], mse_test_bw[30],
                                         msete_pcr, msete_lasso))

ggplot(data = valores_testMSE, aes(x = metodo, y = MSE_te)) +
  geom_col(width = 0.5, fill="#2b602c") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+ xlab("Método") + ylab("MSE Test")              

```



## Enfoque problema de la clasificación


Un mejor enfoque para el problema, es considerarlo como  un problema de clasificación multiclase, por tanto probaremos ahora con algunos clasificadores y tambien comparar desempeños


```{r}
rm(X_tr,Y_tr,X_te,Y_te, test.mat, pred)
```


### Downsampling


```{r}
# Agrupando las canciones por decadas, las canciones de las decadas 20 y 40 
# se ingresan a una misma categoría
  data_clas<-data %>% 
  mutate(decades=sapply(year,function(x){x-x%%10})) %>% 
  mutate(decades=sapply(decades,function(x){ifelse(x<1950,1940,x)})) %>% 
  dplyr::select(-c(year))
```



```{r}
anios<- unique(data_clas$decades)[unique(data_clas$decades)>1940]
muestrabal<-sapply(anios,function(x){
  set.seed(1)
  sample(  which(data_clas$decades==x),2500,replace = F)}) %>% as.vector()
data_clas<-data_clas[muestrabal,]
set.seed(1)
train<-sample(1:nrow(data_clas),p*nrow(data_clas))

```


Nuestro dataset tiene algunas características que pueden dificultar la tarea. Primero se encuentra altamente desbalanceado, es decir pocas categorias (años de lanzamiento) agrupan un volumen imporante de los datos, lo cual estorba el aprendizaje para categorías de menor volumen. Por otra parte existen muchas categorias, es decir muchos años por predecir, esto aumenta el costo computacional al  ajustar un modelo adecuado. Así se realizan los siguientes ajustes en el dataset


1. Agrupamos las piezas musicales por  década del lanzamiento
1. Seleccionamos aleatoriamente una muestra de 1000 ejemplos por década.

La gráfica muestra la frecuencia por clases en el conjunto balanceado.

```{r fig.cap='Dataset balanceado'}
ggplot(data_clas) + aes(decades)+geom_histogram()
```


Como parte de la exploración del conjunto de datos, tratamos de identificar alguna variable que pueda ser buen discriminante de las clases. En los gráficos de muestra la variabilidad de la media de los tracks agrupados por décadas tanto en las variables `TimbreAvg`y `TimbreCov`. Se muestra la dispersión

```{r fig.cap='Dispersión de los décadas sobre TimbreAvg y TimbreCov '}
p1<-data_clas %>% 
  dplyr::select(decades,starts_with('TimbreAvg')) %>% 
  gather('TimbreAvg','Val',starts_with('TimbreAvg'))%>% 
  group_by(decades,TimbreAvg) %>% 
  summarise(mean=mean(Val)) %>% 
  ggplot() + 
  aes(x=as.factor(decades),y=TimbreAvg,fill=mean) +
  geom_tile()+
  scale_fill_gradient(low="green", high="red")+
  labs(x='Década de lanzamiento')+
  theme(legend.position = "none")


p2<-data_clas %>% 
  dplyr::select(decades,starts_with('TimbreCov')) %>% 
  gather('TimbreCov','Val',starts_with('TimbreCov'))%>% 
  group_by(decades,TimbreCov) %>% 
  summarise(mean=mean(Val)) %>% 
  ggplot() + 
  aes(x=as.factor(decades),y=TimbreCov,fill=mean) +
  geom_tile() + 
  scale_fill_gradient(low="green", high="red")+
  labs(x='Década de lanzamiento')+
  theme(legend.position = "none")


grid.arrange(p1,p2,ncol=2)
```


Los gráficos muestran un fuerte sobreempalme de las distribuciones de los datos sobre las variables de interés incluso en las que tienen una 'mayor variabilidad', tal y como se observa:

```{r fig.cap='Distribución de los datos'}


p1<-data_clas %>% 
  dplyr::select(decades,TimbreAvg1) %>% 
  ggplot() + 
  aes(x=TimbreAvg1,color= as.factor(decades)) +
  geom_density()+
  labs(title ='TimbreAvg1' )+
  theme(legend.position = "none")


p2<-data_clas %>% 
  dplyr::select(decades,TimbreAvg2) %>% 
  ggplot() + 
  aes(x=TimbreAvg2,color= as.factor(decades)) +
  geom_density()+
  labs(title ='TimbreAvg2' )+
  theme(legend.position = "none")


p3<-data_clas %>% 
  dplyr::select(decades,TimbreAvg3) %>% 
  ggplot() + 
  aes(x=TimbreAvg3,color= as.factor(decades)) +
  geom_density()+
  labs(title ='TimbreAvg3' )+
  theme(legend.position = "none")


p7<-data_clas %>% 
  dplyr::select(decades,TimbreAvg7) %>% 
  ggplot() + 
  aes(x=TimbreAvg7,color= as.factor(decades)) +
  geom_density()+
  labs(title ='TimbreAvg7' )+
  theme(legend.position = "none")

grid.arrange(p1,p2,p3,p7,ncol=2)
```


### Regresión multinomial con Lasso

Usamos un modelo multinomial con restricción Lasso para disminuir la cantidad de variables

```{r}
predictor<-names(data_clas)!='decades'

mn.lasso<-cv.glmnet(x= as.matrix(data_clas[train,predictor]),
                    y=data_clas$decades[train],
                    nfolds = 3,
                    family = "multinomial", 
                    alpha = 1
                    )
```


En vista, que el dataset balanceado tiene 7 clases, ajustamos un modelo de regresión multiclase, (glm de familia multinomial). Se *cross-validation* con 10 folds y se ajusta $\lambda$ que minimice el error de clasificación.

* **Predicción**

Se presenta la matriz de confusión del modelo con el conjunto de prueba, se tiene un *accuracy* de 0.41

```{r}

pred<-predict(mn.lasso,
              newx = as.matrix(data_clas[-train,predictor]),
             s = "lambda.min", 
             type = "class")

CM<-table(data_clas$decades[-train],pred)

cm<-xtable(CM, align="r|rrrrrrr", caption = "Matriz de confusión modelo multinomial") %>%
  print.xtable(
    floating.environment="table", # use table* environment
    include.rownames=TRUE,
    table.placement="!t",
    comment = FALSE,
    caption.placement = 'top',print.results = FALSE
  )

```

`r toString(cm)`


```{r include=FALSE}
ccm<-caret::confusionMatrix(as.factor(data_clas$decades[-train]),as.factor(pred))

```


### Regresión multinomial con componentes principales

De nuevo para obtener un modelo reducido, probamos un modelo basado en componentes principales. Para escoger la cantidad de componentes evaluamos el **accuracy** de modelos con diferente cantidad de componentes


```{r}
pca.data<-prcomp(data_clas[train,predictor])
```

* **Predicción**


```{r include=FALSE}

npca_test<-seq(5,70,by=5)
acc_pca<-rep(0,length(npca_test))
pos<-1

for(i in npca_test)
{
  
  pca_train_df<-data.frame(decade=data_clas$decades[train],x=pca.data$x[,c(1:i)])

pca.x.test<-as.matrix(data_clas[-train,predictor])%*%pca.data$rotation[,c(1:i)]

pca_test_df<-data.frame(decade=data_clas$decades[-train],x=pca.x.test)
names_df<-c('decades',sapply(1:i,function(x){paste('PC',x,sep='')}))

names(pca_train_df)<-names_df
names(pca_test_df)<-names_df

mod.multinom.pca<-nnet::multinom(decades~.,data=pca_train_df)
pred<-predict(mod.multinom.pca,
              newdata=pca_test_df[,-1],type='class')

acc_pca[pos]<-ifelse(pca_test_df$decades==pred,1,0) %>% mean()
pos<-pos+1
  }

```

Se muestra en el gráfico, el cambio de  *accuracy* con el número de componentes y la matriz de confusión. El *accuracy* es de 0.34 

```{r fig.cap='Cantidad de PCA y acc'}
ggplot()+
  aes(npca_test,acc_pca)+
  geom_point()+
  geom_line()+
  labs(x='Cantidad de PCA',y='acc')
```



```{r}
CM<-table(pca_test_df$decades,pred)

cm<-xtable(CM, align="r|rrrrrrr", caption = "Matriz de confusión PCR") %>%
  print.xtable(
    floating.environment="table", # use table* environment
    include.rownames=TRUE,
    table.placement="!t",
    comment = FALSE,
    caption.placement = 'top',print.results = FALSE
  )
```

`r toString(cm)`


### Otros métodos de clasificación

Una de las soluciones comunes para el problema es el uso de clasificadores tales como *support vector machine*, redes neuronales, boosting o *random forest*. Se presenta el resultado de las matrices de confusión.

* *SVM*



Se ajuste un modelo *SVM* con kernel lineal para la tarea de clasificación, se presenta  la tabla de confusión. El accuracy es de 0. 44

```{r}
cm.svm <- read_table2("docs/svm_test_table.txt")
row.names(cm.svm)<-cm.svm$"1940"
cm.svm<-cm.svm[,-1]


cm<-xtable(cm.svm, align="r|rrrrrrr", caption = "Matriz de confusión SVM") %>%
  print.xtable(
    floating.environment="table", # use table* environment
    include.rownames=TRUE,
    table.placement="!t",
    comment = FALSE,
    caption.placement = 'top',print.results = FALSE
  )




```

`r toString(cm)`

* *Red neuronal*


```{r}
nn.metrics<-read.table("nn_test_metric.txt", row.names = 1)
cm<-xtable(nn.metrics, align="r|rrrrrrrrrrr", caption = "Matriz de confusión NN") %>%
  print.xtable(
    floating.environment="table", # use table* environment
    include.rownames=TRUE,
    table.placement="!t",
    comment = FALSE,
    caption.placement = 'top',print.results = FALSE
  )

```

`r toString(cm)`


Ajustamos a una red neuronal con una sola capa de procesamiento de 15 neuronas, con la salida de clasificación *softmax*. Se presenta el resumen correspondiente:

```{r}
cm.nn<-read_table2("docs/nn_test_table.txt")

row.names(cm.nn)<-cm.nn$"1940"
cm.nn<-cm.nn[,-1]


cm<-xtable(cm.nn, align="r|rrrrrrr", caption = "Matriz de confusión NN") %>%
  print.xtable(
    floating.environment="table", # use table* environment
    include.rownames=TRUE,
    table.placement="!t",
    comment = FALSE,
    caption.placement = 'top',print.results = FALSE
  )

```






```{r}
cm.nn<-read_table2("docs/nn_test_table.txt")
row.names(cm.nn)<-cm.nn$"1940"
cm.nn<-cm.nn[,-1]


cm<-xtable(cm.nn, align="r|rrrrrrr", caption = "Matriz de confusión NN") %>%
  print.xtable(
    floating.environment="table", # use table* environment
    include.rownames=TRUE,
    table.placement="!t",
    comment = FALSE,
    caption.placement = 'top',print.results = FALSE
  )


```

`r toString(cm)`

Conclusiones
=============





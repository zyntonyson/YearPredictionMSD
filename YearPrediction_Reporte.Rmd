---
title: "Aplicación de modelos de regresión para predecir el año de lanzamiento de una canción a partir de las características del audio"
affiliation:
  ## use one only of the following
  # author-columnar: true         ## one column per author
  institution-columnar: true  ## one column per institution (multiple autors eventually)
  # wide: true                  ## one column wide author/affiliation fields

  institution:
    - name: Estudiantes de la maestría en cómputo estadístico
      department: CENTRO DE INVESTIGACIÓN EN MATEMÁTICAS AC
      location: Unidad Monterrey
      mark: 1
      author:
        - name: Aguayo M, Ester
        - name: Castillo C, Román
    
abstract: |
  Se presenta el trabajo como reporte final de la materia 'Cómputo Estadístico', se explora la  eficacia de métodos lineales y lineales generalizados para la predicción del año de lanzamiento de una canción. Tambien se presenta la comparacíón con otros métodos de clasificación
header-includes:
  \usepackage{graphicx}
  \usepackage{amsmath}  
  \usepackage{algorithm}
  \usepackage{algorithmic}
  \usepackage{array}
  \renewcommand{\figurename}{Figura}
  \renewcommand{\tablename}{Tabla}
  \setcounter{tocdepth}{5} 
  \setcounter{secnumdepth}{5} 
number_sections: TRUE 
bibliography: mybibfile.bib
output: rticles::ieee_article
---

```{r setup, include=FALSE}
library(readxl)
library(tidyverse)
library(GGally)
library(corrplot)
library(knitr)
library(xtable)
library(broom)
library(gridExtra)
library(leaps)
library(MASS)
library(glmnet)


knitr::opts_chunk$set(echo = FALSE, message=FALSE, out.width='60%', fig.pos= "ht",fig.align='center' , warning = FALSE,comment=NA)

#Datos crudos
data <- read_csv("data/YearPredictionMSD.txt", 
                 col_names = FALSE)

# Agregar nombres a columnas para identificacion
# 1-year
# 2-13 TimbreAvg1-12
# 14-91 TimbreCov1-78
# 

names(data)<-c('year',
               sapply(1:12,function(x){paste('TimbreAvg',x,sep='')}),
               sapply(1:78,function(x){paste('TimbreCov',x,sep='')}))

#*********************** SEPARAR TRAIN Y TEST ***************************


#importante la semilla
n = nrow(data)
p<-0.6
set.seed(1)
muestra <- sample(1:nrow(data), n*p)

```


Introducción
=============

Los métodos de predicción consiste una herramienta fundamental en esta época de la abundancia de datos. Muchos negocios, día con  día producen enormes cantidades de nueva información, por ejemplo en la industría musical, horas de nueva música. Una tarea de interés, es poder determinar el año de lanzamiento. Como  parte de los recursos para la solución de esta tarea, se cuenta con el *Million Song Dataset* (MSD) que es un *data* de acceso gratuito de características de audio y metadatos de un millón de piezas musicales contemporaneas. Entre los metadatos disponibles se encuetra el año de lanzamiento de cada pieza.

## Objetivos

Usando el **MSD** se plantean los siguientes objetivos

1. Considerando al año de lanzamiento como variable númerica continua, ajustar un modelo de regresión, usando como predictores características del audio

1. Ajustar un clasificador basado en regresión multiclase para predecir el año de lanzamiento de una canción

1. Comparar los resultados con otros clasificadores tales como SVM y NN


Métodos y resultados
=============

## Análisis exploratorio

**YearPredictionMSD** es un *subset* del **MSD**, destinado a la tarea de prediccón del  año de lanzamiento de un track. Esta formado por 515345 registros de canciones correspondientes a 90 características tomadas de cada composición. Las características fueron obtenidas del API de **Echo Nest**. Donde cada composición fue divida en doce segmentos. De los cuales se recuperan los promedios y covarianzas de  todos ellos.

Con respecto a la cantidad de registros por año de lanzamiento, el conjunto de datos se encuetra altamente desbalanceado. Más del 80% correponde a canciones a partir de la primera decada del año 2000.

```{r fig.cap='Distribución de las canciones por año'}
ggplot(data) + aes(year)+geom_histogram()
```





```{r }
# Presenta el MSE a diferente número de predictores
mse_plot<-function(mse,sub,ylab)
{
  plot(1:length(mse),mse_train,
     type='b',
     col='darkblue',
     pch=19,
     xlab='Cantidad de predictores',
     ylab=ylab,
     #main = 'Subset Selection',
     sub = sub)
                        
points(which.min(mse),min(mse),col='red',pch='*',cex=2)
text(which.min(mse),min(mse),labels =bquote(paste('Mejor modelo:',.(which.min(mse)),' predictores')),pos = 3, cex=0.8 )

  
  }
```



##  Regresión múltiple

```{r}
# Seleccion datos de entrenamiento
#dividimos nuestros datos en prueba y validación
X_tr = as.matrix(data[muestra,-1])
Y_tr = as.matrix(data[muestra,1])

X_te = as.matrix(data[-muestra,-1])
Y_te = as.matrix(data[-muestra,1])

```



### Regresión ordinaria (mejor subconjunto)

```{r}
nVar<-90
# seleccion mejor subconjunto de variables

modelo_fw <- regsubsets(X_tr, Y_tr, method = "forward",  nvmax = nVar)
modelo_bw <- regsubsets(X_tr, Y_tr, method = "backward", nvmax = nVar)

```

 * Forward stepwise selection
 
```{r fig.cap='Forward stepwise selection'}
#modelo con paso fwd
msum_fwd  <- summary(modelo_fw )

# Calculo del MSE train
test.mat<-model.matrix(year~.,data=data)
mse_test<-rep(0,nVar)
mse_train<-rep(0,nVar)

for (i in 1:nVar)
{
   coefi = coef(modelo_fw, id=i)
   pred = test.mat[,names(coefi)]%*%coefi
   mse_train[i] = mean((data$year[muestra]-pred[muestra])^2)
   mse_test[i] = mean((data$year[-muestra]-pred[-muestra])^2)
  
}

#grafica
#grafica
par(mfrow=c(2,2))
plot(msum_fwd$adjr2 ,xlab="Núm Variables",ylab="R cuadrado aj",type="l", pch=19, col="#95505c")
points(which.max(msum_fwd$adjr2),max(msum_fwd$adjr2),col='red',pch='*',cex=2)
plot(msum_fwd$bic ,xlab="Núm Variables", ylab="Bic",type="l", pch=19, col="#5c9550")
points(which.min(msum_fwd$bic),min(msum_fwd$bic),col='red',pch='*',cex=2)
plot(msum_fwd$cp ,xlab="Núm Variables",ylab="Cp", type="l", pch=19, col="#505c95")
points(which.min(msum_fwd$cp),min(msum_fwd$cp),col='red',pch='*',cex=2)
plot(1:nVar,mse_train,xlab="Núm Variables",ylab="MSE", type="l", pch=19, col="firebrick")
lines(1:nVar,mse_test,type="l", pch=19, col="firebrick")
points(which.min(mse_test),min(mse_test),col='red',pch='*',cex=2)

```
 

   * Forward stepwise selection


```{r  fig.cap='Backward stepwise selection'}
msum_bwd  <- summary(modelo_bw )
#grafica
# Calculo del MSE train
#test.mat<-model.matrix(year~.,data=data)
mse_test<-rep(0,nVar)
mse_train<-rep(0,nVar)

for (i in 1:nVar)
{
   coefi = coef(modelo_bw, id=i)
   pred = test.mat[,names(coefi)]%*%coefi
   mse_train[i] = mean((data$year[muestra]-pred[muestra])^2)
   mse_test[i] = mean((data$year[-muestra]-pred[-muestra])^2)
  
}

#grafica
par(mfrow=c(2,2))
plot(msum_bwd$adjr2 ,xlab="Núm Variables",ylab="R cuadrado aj",type="l", pch=19, col="#95505c")
points(which.max(msum_bwd$adjr2),max(msum_bwd$adjr2),col='red',pch='*',cex=2)
plot(msum_bwd$bic ,xlab="Núm Variables", ylab="Bic",type="l", pch=19, col="#5c9550")
points(which.min(msum_bwd$bic),min(msum_bwd$bic),col='red',pch='*',cex=2)
plot(msum_bwd$cp ,xlab="Núm Variables",ylab="Cp", type="l", pch=19, col="#505c95")
points(which.min(msum_bwd$cp),min(msum_bwd$cp),col='red',pch='*',cex=2)
plot(1:nVar,mse_train,xlab="Núm Variables",ylab="MSE", type="l", pch=19, col="firebrick")
lines(1:nVar,mse_test,type="l", pch=19, col="firebrick")
points(which.min(mse_test),min(mse_test),col='red',pch='*',cex=2)

```




### Regresión con contracción  Lasso

```{r eval=FALSE}
# REGRESION LASSO


data_mat_tr <- model.matrix(year ~ ., data = data)

# Conjunto de valores de lambda 
lambda = 10 ^ seq(from = -4, to = 4, length = 100)
# 10-fold cross validation para obtener el mejor lambda
set.seed(12)
cv.ridge <- cv.glmnet(x = data_mat, y = Y, alpha = 1, lambda = lambda, thresh = 1e-12, type.measure="mse")

plot(cv.ridge)  

cv.ridge$lambda.min
glmnet(X,Y)
# Se excluye la primera columna con los nombres de las universidades
modelo.ridge <- glmnet(X, Y, alpha = 0)
# Coeficientes del modelo
predict(modelo.ridge, type = "coefficients", s = cv.ridge$lambda.min)

```



###  Regresión con componentes principales


## Enfoque problema de la clasificación


Un mejor enfoque para el problema, es considerarlo como  un problema de clasificación multiclase, por tanto probaremos ahora con algunos clasificadores y tambien comparar desempeños


```{r}
rm(X_tr,Y_tr,X_te,Y_te, test.mat, pred)
```


### Downsampling


```{r}
# Agrupando las canciones por decadas, las canciones de las decadas 20 y 40 
# se ingresan a una misma categoría
  data_clas<-data %>% 
  mutate(decades=sapply(year,function(x){x-x%%10})) %>% 
  mutate(decades=sapply(decades,function(x){ifelse(x<1950,1940,x)})) %>% 
  dplyr::select(-c(year))
```



```{r}
anios<- unique(data_clas$decades)[unique(data_clas$decades)>1940]
muestrabal<-sapply(anios,function(x){
  set.seed(1)
  sample(  which(data_clas$decades==x),2500,replace = F)}) %>% as.vector()
data_clas<-data_clas[muestrabal,]
set.seed(1)
train<-sample(1:nrow(data_clas),p*nrow(data_clas))

```


Nuestro dataset tiene algunas características que pueden dificultar la tarea. Primero se encuentra altamente desbalanceado, es decir pocas categorias (años de lanzamiento) agrupan un volumen imporante de los datos, lo cual estorba el aprendizaje para categorías de menor volumen. Por otra parte existen muchas categorias, es decir muchos años por predecir, esto aumenta el costo computacional al  ajustar un modelo adecuado. Así se realizan los siguientes ajustes en el dataset


1. Agrupamos las piezas musicales por  década del lanzamiento
1. Seleccionamos aleatoriamente una muestra de 1000 ejemplos por década.

La gráfica muestra la frecuencia por clases en el conjunto balanceado.

```{r fig.cap='Dataset balanceado'}
ggplot(data_clas) + aes(decades)+geom_histogram()
```


Como parte de la exploración del conjunto de datos, tratamos de identificar alguna variable que pueda ser buen discriminante de las clases. En los gráficos de muestra la variabilidad de la media de los tracks agrupados por décadas tanto en las variables `TimbreAvg`y `TimbreCov`. Se muestra la dispersión

```{r fig.cap='Dispersión de los décadas sobre TimbreAvg y TimbreCov '}
p1<-data_clas %>% 
  dplyr::select(decades,starts_with('TimbreAvg')) %>% 
  gather('TimbreAvg','Val',starts_with('TimbreAvg'))%>% 
  group_by(decades,TimbreAvg) %>% 
  summarise(mean=mean(Val)) %>% 
  ggplot() + 
  aes(x=as.factor(decades),y=TimbreAvg,fill=mean) +
  geom_tile()+
  scale_fill_gradient(low="green", high="red")+
  labs(x='Década de lanzamiento')+
  theme(legend.position = "none")


p2<-data_clas %>% 
  dplyr::select(decades,starts_with('TimbreCov')) %>% 
  gather('TimbreCov','Val',starts_with('TimbreCov'))%>% 
  group_by(decades,TimbreCov) %>% 
  summarise(mean=mean(Val)) %>% 
  ggplot() + 
  aes(x=as.factor(decades),y=TimbreCov,fill=mean) +
  geom_tile() + 
  scale_fill_gradient(low="green", high="red")+
  labs(x='Década de lanzamiento')+
  theme(legend.position = "none")


grid.arrange(p1,p2,ncol=2)
```


Los gráficos muestran un fuerte sobreempalme de las distribuciones de los datos sobre las variables de interés incluso en las que tienen una 'mayor variabilidad', tal y como se observa:

```{r fig.cap='Distribución de los datos'}


p1<-data_clas %>% 
  dplyr::select(decades,TimbreAvg1) %>% 
  ggplot() + 
  aes(x=TimbreAvg1,color= as.factor(decades)) +
  geom_density()+
  labs(title ='TimbreAvg1' )+
  theme(legend.position = "none")


p2<-data_clas %>% 
  dplyr::select(decades,TimbreAvg2) %>% 
  ggplot() + 
  aes(x=TimbreAvg2,color= as.factor(decades)) +
  geom_density()+
  labs(title ='TimbreAvg2' )+
  theme(legend.position = "none")


p3<-data_clas %>% 
  dplyr::select(decades,TimbreAvg3) %>% 
  ggplot() + 
  aes(x=TimbreAvg3,color= as.factor(decades)) +
  geom_density()+
  labs(title ='TimbreAvg3' )+
  theme(legend.position = "none")


p7<-data_clas %>% 
  dplyr::select(decades,TimbreAvg7) %>% 
  ggplot() + 
  aes(x=TimbreAvg7,color= as.factor(decades)) +
  geom_density()+
  labs(title ='TimbreAvg7' )+
  theme(legend.position = "none")

grid.arrange(p1,p2,p3,p7,ncol=2)
```


### Regresión multinomial con Lasso



```{r}
predictor<-names(data_clas)!='decades'

mn.lasso<-cv.glmnet(x= as.matrix(data_clas[train,predictor]),
                    y=data_clas$decades[train],
                    nfolds = 3,
                    family = "multinomial", 
                    alpha = 1
                    )
```


hjklñ

```{r}
plot(mn.lasso)
```

* **Predicción**


```{r}

pred<-predict(mn.lasso,
              newx = as.matrix(data_clas[-train,predictor]),
             s = "lambda.min", 
             type = "class")

CM<-table(data_clas$decades[-train],pred)

cm<-xtable(CM, align="r|rrrrrrr", caption = "Matriz de confusión modelo multinomial") %>%
  print.xtable(
    floating.environment="table", # use table* environment
    include.rownames=TRUE,
    table.placement="!t",
    comment = FALSE,
    caption.placement = 'top',print.results = FALSE
  )

```

`r toString(cm)`


```{r include=FALSE}
ccm<-caret::confusionMatrix(as.factor(data_clas$decades[-train]),as.factor(pred))

```


### Regresión multinomial con componentes principales


```{r}
pca.data<-prcomp(data_clas[,predictor])

```


### Otros métodos de clasificación



Conclusiones
=============





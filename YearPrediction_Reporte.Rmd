---
title: "Aplicación de modelos de regresión para predecir el año de lanzamiento de una canción a partir de las características del audio"
affiliation:
  ## use one only of the following
  # author-columnar: true         ## one column per author
  institution-columnar: true  ## one column per institution (multiple autors eventually)
  # wide: true                  ## one column wide author/affiliation fields

  institution:
    - name: Estudiantes de la maestría en cómputo estadístico
      department: CENTRO DE INVESTIGACIÓN EN MATEMÁTICAS AC
      location: Unidad Monterrey
      mark: 1
      author:
        - name: Aguayo M, Ester
        - name: Castillo C, Román
    
abstract: |
  El aleaje es un fénomeno ampliamente estudiado y descrito usando modelos estocásticos. En este trabajo, a modo de ejercicio se usan técnicas multivariadas en busca de información de interés relativa al oleaje
header-includes:
  \usepackage{graphicx}
  \usepackage{amsmath}  
  \usepackage{algorithm}
  \usepackage{algorithmic}
  \renewcommand{\figurename}{Figura}
  \renewcommand{\tablename}{Tabla}
  \setcounter{tocdepth}{5} 
  \setcounter{secnumdepth}{5} 
  #\usepackage{graphicx} para permitir insertar imagnes con knitr
  #\setcounter{tocdepth}{5} 
  #\setcounter{secnumdepth}{5} permitir numeracion de secciones 
number_sections: TRUE 
bibliography: mybibfile.bib
output: rticles::ieee_article
---

```{r setup, include=FALSE}
library(readxl)
library(tidyverse)
library(GGally)
library(corrplot)
library(knitr)
library(xtable)
library(broom)
library(gridExtra)
library("leaps")
library("MASS")
library("tidyverse")
library("magrittr")
library("glmnet")


knitr::opts_chunk$set(echo = FALSE, message=FALSE, out.width='60%', fig.pos= "ht",fig.align='center' , warning = FALSE,comment=NA)

#Datos crudos
data <- read_csv("data/YearPredictionMSD.txt", 
                 col_names = FALSE)

# Agregar nombres a columnas para identificacion
# 1-year
# 2-13 TimbreAvg1-12
# 14-91 TimbreCov1-78
# 

names(data)<-c('year',
               sapply(1:12,function(x){paste('TimbreAvg',x,sep='')}),
               sapply(1:78,function(x){paste('TimbreCov',x,sep='')}))

#*********************** SEPARAR TRAIN Y TEST ***************************

#dividimos nuestros datos en prueba y validación

#importante la semilla
n = nrow(data)
p<-0.6
set.seed(1)
muestra <- sample(1:nrow(data), n*p)

```


Introducción
=============

## Objetivos




Métodos y resultados
=============

## Análisis exploratorio


##  Regresión múltiple

```{r}
# Preparar data

muestra <- sample(1:nrow(data), n*.6)

#X_tr = as.matrix(data[muestra,-1])
#Y_tr = as.matrix(data[muestra,1])

#X_te = as.matrix(data[-muestra,-1])
#Y_te = as.matrix(data[-muestra,1])



```



### Regresión ordinaria (mejor subconjunto)

```{r}
# seleccion mejor subconjunto de variables
nVar<-20
modelo_fw <- regsubsets(year~.,data=data[muestra,], method = "forward",  nvmax = nVar)
modelo_bw <- regsubsets(year~.,data=data[muestra,], method = "backward", nvmax = nVar)

#modelo con paso fwd

msum_fwd  <- summary(modelo_fw )
#grafica
par(mfrow=c(3,2))
plot(msum_fwd$rsq ,xlab="Núm Variables",ylab="R cuadrado",type="b", pch=19, col="#95505c")
plot(msum_fwd$bic ,xlab="Núm Variables", ylab="Bic",type="b", pch=19, col="#5c9550")
plot(msum_fwd$cp ,xlab="Núm Variables",ylab="Cp", type="b", pch=19, col="#505c95")

par(mfrow=c(1,1))

#modelo con paso backward

msum_bwd  <- summary(modelo_bw )
#grafica
par(mfrow=c(3,1))
plot(msum_bwd$rsq ,xlab="Núm Variables",ylab="R cuadrado",type="b", pch=19, col="#95505c")
plot(msum_bwd$bic ,xlab="Núm Variables", ylab="Bic",type="b", pch=19, col="#5c9550")
plot(msum_bwd$cp ,xlab="Núm Variables",ylab="Cp", type="b", pch=19, col="#505c95")

par(mfrow=c(1,1))

#aun seleccionando todas las variables el R_cuadrado es muy bajo, del .15, por lo que quizá la regresion no es la mejor opción
# veremos las 15 variables más importantes

coef_bw <- coef(modelo_bw, 15)
coef_fw <- coef(modelo_fw, 15)

# estas son las variables en las que difieren los modelos
names(coef_bw) [is.na ( match(names(coef_bw),names( coef_fw)) )]
names(coef_fw) [is.na ( match(names(coef_fw),names( coef_bw)) )]

mse_test_new <- vector()
for (i in 1:20){
  coefs <- coef(m_full,i)
  indice <- match(names(coefs)[-1],let)
  X1_test <- cbind(1,X_test[,indice])
  Y_gorro <- X1_test%*%coefs
  mse_test_new <- c(mse_test_new, mean((Y_test-Y_gorro)^2))    
}

```


### Regresión con contracción  Lasso

```{r}
# REGRESION LASSO


data_mat_tr <- model.matrix(year ~ ., data = data)

# Conjunto de valores de lambda 
lambda = 10 ^ seq(from = -4, to = 4, length = 100)
# 10-fold cross validation para obtener el mejor lambda
set.seed(12)
cv.ridge <- cv.glmnet(x = data_mat, y = Y, alpha = 1, lambda = lambda, thresh = 1e-12, type.measure="mse")

plot(cv.ridge)  

cv.ridge$lambda.min
glmnet(X,Y)
# Se excluye la primera columna con los nombres de las universidades
modelo.ridge <- glmnet(X, Y, alpha = 0)
# Coeficientes del modelo
predict(modelo.ridge, type = "coefficients", s = cv.ridge$lambda.min)

```



###  Regresión con componentes principales


## Enfoque problema de la clasificación

### Downsampling

### Regresión multinomial con Lasso

### Regresión multinomial con componentes principales

### Otros métodos de clasificación



Conclusiones
=============


Acknowledgment {#acknowledgment}
==============

The authors would like to thank...

Bibliography styles
===================

Here are two sample references: @Feynman1963118 [@Dirac1953888].

\newpage
References {#references .numbered}
==========

---
title: "Aplicación de modelos de regresión para predecir el año de lanzamiento de una canción a partir de las características del audio"
affiliation:
  ## use one only of the following
  # author-columnar: true         ## one column per author
  institution-columnar: true  ## one column per institution (multiple autors eventually)
  # wide: true                  ## one column wide author/affiliation fields

  institution:
    - name: Estudiantes de la maestría en cómputo estadístico
      department: CENTRO DE INVESTIGACIÓN EN MATEMÁTICAS AC
      location: Unidad Monterrey
      mark: 1
      author:
        - name: Aguayo M, Ester
        - name: Castillo C, Román
    
abstract: |
  El aleaje es un fénomeno ampliamente estudiado y descrito usando modelos estocásticos. En este trabajo, a modo de ejercicio se usan técnicas multivariadas en busca de información de interés relativa al oleaje
header-includes:
  \usepackage{graphicx}
  \usepackage{amsmath}  
  \usepackage{algorithm}
  \usepackage{algorithmic}
  \renewcommand{\figurename}{Figura}
  \renewcommand{\tablename}{Tabla}
  \setcounter{tocdepth}{5} 
  \setcounter{secnumdepth}{5} 
number_sections: TRUE 
bibliography: mybibfile.bib
output: rticles::ieee_article
---

```{r setup, include=FALSE}
library(readxl)
library(tidyverse)
library(GGally)
library(corrplot)
library(knitr)
library(xtable)
library(broom)
library(gridExtra)
library("leaps")
library("MASS")
library("tidyverse")
library("magrittr")
library("glmnet")


knitr::opts_chunk$set(echo = FALSE, message=FALSE, out.width='60%', fig.pos= "ht",fig.align='center' , warning = FALSE,comment=NA)

#Datos crudos
data <- read_csv("data/YearPredictionMSD.txt", 
                 col_names = FALSE)

# Agregar nombres a columnas para identificacion
# 1-year
# 2-13 TimbreAvg1-12
# 14-91 TimbreCov1-78
# 

names(data)<-c('year',
               sapply(1:12,function(x){paste('TimbreAvg',x,sep='')}),
               sapply(1:78,function(x){paste('TimbreCov',x,sep='')}))

#*********************** SEPARAR TRAIN Y TEST ***************************


#importante la semilla
n = nrow(data)
p<-0.6
set.seed(1)
muestra <- sample(1:nrow(data), n*p)

```


Introducción
=============

## Objetivos




Métodos y resultados
=============

## Análisis exploratorio

```{r}
# Presenta el MSE a diferente número de predictores
mse_plot<-function(mse,sub,ylab)
{
  plot(1:length(mse),mse_train,
     type='b',
     col='darkblue',
     pch=19,
     xlab='Cantidad de predictores',
     ylab=ylab,
     #main = 'Subset Selection',
     sub = sub)
                        
points(which.min(mse),min(mse),col='red',pch='*',cex=2)
text(which.min(mse),min(mse),labels =bquote(paste('Mejor modelo:',.(which.min(mse)),' predictores')),pos = 3, cex=0.8 )

  
  }
```



##  Regresión múltiple

```{r}
# Seleccion datos de entrenamiento
#dividimos nuestros datos en prueba y validación
X_tr = as.matrix(data[muestra,-1])
Y_tr = as.matrix(data[muestra,1])

X_te = as.matrix(data[-muestra,-1])
Y_te = as.matrix(data[-muestra,1])

```



### Regresión ordinaria (mejor subconjunto)

```{r}
nVar<-90
# seleccion mejor subconjunto de variables

modelo_fw <- regsubsets(X_tr, Y_tr, method = "forward",  nvmax = nVar)
modelo_bw <- regsubsets(X_tr, Y_tr, method = "backward", nvmax = nVar)

```

 * Forward stepwise selection
 
```{r}



#modelo con paso fwd
msum_fwd  <- summary(modelo_fw )

# Calculo del MSE train
test.mat<-model.matrix(year~.,data=data)
mse_test<-rep(0,nVar)
mse_train<-rep(0,nVar)

for (i in 1:nVar)
{
   coefi = coef(modelo_fw, id=i)
   pred = test.mat[,names(coefi)]%*%coefi
   mse_train[i] = mean((data$year[muestra]-pred[muestra])^2)
   mse_test[i] = mean((data$year[-muestra]-pred[-muestra])^2)
  
}

#grafica
par(mfrow=c(2,2))
plot(msum_fwd$rsq ,xlab="Núm Variables",ylab="R cuadrado",type="l", pch=19, col="#95505c")
plot(msum_fwd$bic ,xlab="Núm Variables", ylab="Bic",type="l", pch=19, col="#5c9550")
plot(msum_fwd$cp ,xlab="Núm Variables",ylab="Cp", type="l", pch=19, col="#505c95")
plot(1:nVar,mse_train,xlab="Núm Variables",ylab="MSE", type="l", pch=19, col="firebrick")
lines(1:nVar,mse_test,type="l", pch=19, col="firebrick")




```
 


```{r}
msum_bwd  <- summary(modelo_bw )
#grafica
par(mfrow=c(3,1))
plot(msum_bwd$rsq ,xlab="Núm Variables",ylab="R cuadrado",type="b", pch=19, col="#95505c")
plot(msum_bwd$bic ,xlab="Núm Variables", ylab="Bic",type="b", pch=19, col="#5c9550")
plot(msum_bwd$cp ,xlab="Núm Variables",ylab="Cp", type="b", pch=19, col="#505c95")

par(mfrow=c(1,1))
```




### Regresión con contracción  Lasso

```{r}
# REGRESION LASSO


data_mat_tr <- model.matrix(year ~ ., data = data)

# Conjunto de valores de lambda 
lambda = 10 ^ seq(from = -4, to = 4, length = 100)
# 10-fold cross validation para obtener el mejor lambda
set.seed(12)
cv.ridge <- cv.glmnet(x = data_mat, y = Y, alpha = 1, lambda = lambda, thresh = 1e-12, type.measure="mse")

plot(cv.ridge)  

cv.ridge$lambda.min
glmnet(X,Y)
# Se excluye la primera columna con los nombres de las universidades
modelo.ridge <- glmnet(X, Y, alpha = 0)
# Coeficientes del modelo
predict(modelo.ridge, type = "coefficients", s = cv.ridge$lambda.min)

```



###  Regresión con componentes principales


## Enfoque problema de la clasificación

### Downsampling

### Regresión multinomial con Lasso

### Regresión multinomial con componentes principales

### Otros métodos de clasificación



Conclusiones
=============


Acknowledgment {#acknowledgment}
==============

The authors would like to thank...

Bibliography styles
===================

Here are two sample references: @Feynman1963118 [@Dirac1953888].

\newpage
References {#references .numbered}
==========
